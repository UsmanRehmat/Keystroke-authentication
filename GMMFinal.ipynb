{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn import mixture\n",
    "import pandas as pd\n",
    "import re\n",
    "import scipy.stats as stats\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadListOfTextFilesFromDirectoryWalk(path):\n",
    "    \"\"\"Read all text files from given directory and its sudirectories and return list of text files path\"\"\"\n",
    "    files = []\n",
    "    # r=root, d=directories, f = files\n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f:\n",
    "            if '.txt' in file:\n",
    "                files.append(os.path.join(r, file))\n",
    "    return files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateListOfTuplesFromFile(files):\n",
    "#Reading file and create tuple \n",
    "    items = []\n",
    "    for file in files:\n",
    "        filename=file.split('\\\\')[-1].split('.')[0]\n",
    "        f=open(file, \"r\")\n",
    "        for line in f:\n",
    "            words= line.rstrip('\\n').split(sep=\" \")\n",
    "            items.append((words[0],words[1],words[2],filename))\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateListFromFile(file):\n",
    "#Reading file and create tuple \n",
    "    items = []\n",
    "#    iterator = (files,) if not isinstance(files, (tuple, list)) else files\n",
    "#    for file in iterator:\n",
    "    filename=file.split('\\\\')[-1].split('.')[0]\n",
    "    f=open(file, \"r\")\n",
    "    for line in f:\n",
    "        words= line.rstrip('\\n').split(sep=\" \")\n",
    "        items.append((words[0],words[1],words[2],filename))\n",
    "    f.close()\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dataframes\n",
    "def CreateDataFrame(items,columns):\n",
    "    \"\"\"Taking list of tuples and return dataframe\"\"\"\n",
    "    df = pd.DataFrame.from_records(items, columns=['Key', 'EventType','Time','User'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ParseAlphabetsKeys(df):\n",
    "    \"\"\"Return only alphabets records\"\"\"\n",
    "    dfAlphabets=df[df[\"Key\"].str.match('^.*[A-Z]$')]\n",
    "    return dfAlphabets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTimeDifferenceofKeyUpDown(data):\n",
    "    prev=0\n",
    "    rows=[]\n",
    "    for index,row in data.iterrows():\n",
    "        if prev==0 and row[1]==\"KeyDown\":\n",
    "            prevRow=row\n",
    "            prev=1\n",
    "        elif row[1]==\"KeyDown\":\n",
    "            rows.append([ prevRow[0], row[0], int(row[2])- int(prevRow[2]),row[3]])\n",
    "            prevRow=row\n",
    "            \n",
    "        keyDownsList = []\n",
    "        \n",
    "    rows=[]\n",
    "    for row in data:\n",
    "        if row[1]==\"KeyDown\":\n",
    "            keyDownsList.append(row)\n",
    "        elif row[1]==\"KeyUp\":\n",
    "            i=0\n",
    "            for keyDown in keyDownsList:\n",
    "                if row[0]==keyDown[0]:\n",
    "                    rows.append([ keyDown[0], int(row[2])- int(keyDown[2]),row[3]])\n",
    "                    del keyDownsList[i]\n",
    "                    break\n",
    "                i = i + 1\n",
    "    return rows\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTimeDifferenceofKeyDownDown(data):\n",
    "    prev=0\n",
    "    rows=[]\n",
    "    for index,row in data.iterrows():\n",
    "        if prev==0 and row[1]==\"KeyDown\":\n",
    "            prevRow=row\n",
    "            prev=1\n",
    "        elif row[1]==\"KeyDown\":\n",
    "            rows.append([ prevRow[0], row[0], int(row[2])- int(prevRow[2]),row[3]])\n",
    "            prevRow=row\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetDictionaryOfFeatureVectors(keyDownDownTimeDifference):\n",
    "    \"\"\"\n",
    "    Take List of arrays and return dictionary of 26*26 vector for each user\n",
    "    \"\"\"\n",
    "    dictFV=dict()\n",
    "    for xi in keyDownDownTimeDifference:\n",
    "        if xi[3] not in dictFV:\n",
    "            dictFV[xi[3]]=np.zeros(26*26,dtype=object)\n",
    "            \n",
    "        index=(ord(xi[0])-65)*26+np.absolute(ord(xi[1])-65)\n",
    "        if dictFV[xi[3]][index]==0:\n",
    "            dictFV[xi[3]][index]=[]\n",
    "        if xi[2] < 1000:\n",
    "            dictFV[xi[3]][index].append(xi[2])\n",
    "    return dictFV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetGMMFormatDataFromDataFrame(usersFV):\n",
    "    GMMData=[]\n",
    "    for user in usersFV.columns:\n",
    "        maxLength=0\n",
    "        for userF in usersFV[user]:\n",
    "            if userF==0:\n",
    "                userF=[]\n",
    "            featureLenght=len(userF)\n",
    "            if featureLenght > maxLength:\n",
    "                maxLength=featureLenght\n",
    "        userDF=pd.DataFrame(index=range(0,676))\n",
    "        userData=np.zeros((maxLength,676))\n",
    "        row=0\n",
    "        for userF in usersFV[user]:\n",
    "            column=0\n",
    "            if userF==0:\n",
    "                userF=[]\n",
    "            availableValuesCount=len(userF)\n",
    "            sum=0\n",
    "            for value in userF:\n",
    "                userData[column][row]=value\n",
    "                column=column+1\n",
    "                sum=sum+value\n",
    "            if availableValuesCount==0:\n",
    "                mean=0\n",
    "            else:\n",
    "                mean=sum/availableValuesCount\n",
    "            gussianValues=np.random.normal(mean,3,maxLength-availableValuesCount)\n",
    "            for value in gussianValues:\n",
    "            \n",
    "                userData[column][row]=value\n",
    "                column=column+1\n",
    "        \n",
    "            row=row+1\n",
    "        print(userData.shape)\n",
    "        if len(GMMData)==0:\n",
    "            GMMData=userData\n",
    "        else:\n",
    "            GMMData=np.append(GMMData,userData,axis=0)\n",
    "    return GMMData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAverageFeatureVectors(FeatureVectors):\n",
    "    \n",
    "    averageFV= np.zeros(26*26,dtype=object)\n",
    "    index=0\n",
    "    for xi in FeatureVectors:\n",
    "        tempSum=np.array(xi).sum()\n",
    "        if type(xi)== list:\n",
    "            averageFV[index]=tempSum/len(xi)\n",
    "        index=index+1\n",
    "    return averageFV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel(path):\n",
    "    \"\"\"Get path of data files and train a GMM model\"\"\"\n",
    "    files=ReadListOfTextFilesFromDirectoryWalk(path)\n",
    "    # I am training on first 10 users\n",
    "    dataFileFormat=CreateListOfTuplesFromFile(files[0:6:2])\n",
    "    #print(dataFileFormat[0])\n",
    "    df=CreateDataFrame(dataFileFormat,columns=['Key', 'EventType','Time','User'])\n",
    "    alphabetsDF=ParseAlphabetsKeys(df)\n",
    "    keyDownDownTimeDifference=GetTimeDifferenceofKeyDownDown(data=alphabetsDF)\n",
    "    FeatureVectors=GetDictionaryOfFeatureVectors(keyDownDownTimeDifference) \n",
    "    usersFV=pd.DataFrame.from_dict(FeatureVectors)\n",
    "    data= GetGMMFormatDataFromDataFrame(usersFV)\n",
    "    g = mixture.GMM(n_components=3)\n",
    "    print(len(data))\n",
    "    g.fit(data)\n",
    "    return g\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestModel(path,g):\n",
    "    \"\"\"Get path of data files and test a GMM model\"\"\"\n",
    "    GMMData=[]\n",
    "    files=ReadListOfTextFilesFromDirectoryWalk(path)\n",
    "    dataFileFormat=CreateListOfTuplesFromFile(files[0:6:2])\n",
    "    df=CreateDataFrame(dataFileFormat,columns=['Key', 'EventType','Time','User'])\n",
    "    \n",
    "    alphabetsDF=ParseAlphabetsKeys(df)\n",
    "    keyDownDownTimeDifference=GetTimeDifferenceofKeyDownDown(data=alphabetsDF)\n",
    "    FeatureVectors=GetDictionaryOfFeatureVectors(keyDownDownTimeDifference) \n",
    "    usersFV=pd.DataFrame.from_dict(FeatureVectors)\n",
    "    for user in FeatureVectors:\n",
    "        print(user)\n",
    "        data=GetAverageFeatureVectors(FeatureVectors[user])\n",
    "        dataNP=np.array(data,dtype=np.float64)\n",
    "        dataNP[np.isnan(dataNP)]=0\n",
    "        dataNP=dataNP.reshape((1,676))\n",
    "        \n",
    "        \n",
    "        if len(GMMData)==0:\n",
    "            GMMData=dataNP\n",
    "        else:\n",
    "            GMMData=np.append(GMMData,dataNP,axis=0)\n",
    "    print(GMMData.shape)\n",
    "    print(len(GMMData))\n",
    "    \n",
    "    print(g.predict_proba(GMMData))\n",
    "    return g.predict(GMMData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65, 676)\n",
      "(65, 676)\n",
      "(65, 676)\n",
      "195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ammar\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class GMM is deprecated; The class GMM is deprecated in 0.18 and will be  removed in 0.20. Use class GaussianMixture instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\ammar\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\ammar\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\ammar\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\ammar\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.33333333, 0.33333333, 0.33333333])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GMM= TrainModel(\"..\\\\UB_keystroke_dataset\\\\S0\")\n",
    "GMM.weights_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001100\n",
      "002100\n",
      "003100\n",
      "(3, 676)\n",
      "3\n",
      "[[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ammar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "C:\\Users\\ammar\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\ammar\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "predictions=TestModel(\"..\\\\UB_keystroke_dataset\\\\S1\",GMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetKDEFormatDataFromDataFrame(usersFV):\n",
    "    GMMData=[]\n",
    "    TargetUser=[]\n",
    "    for user in usersFV.columns:\n",
    "        print(user)\n",
    "        maxLength=0\n",
    "        for userF in usersFV[user]:\n",
    "            if userF==0:\n",
    "                userF=[]\n",
    "            featureLenght=len(userF)\n",
    "            if featureLenght > maxLength:\n",
    "                maxLength=featureLenght\n",
    "        userDF=pd.DataFrame(index=range(0,676))\n",
    "        userData=np.zeros((maxLength,676))\n",
    "        a=np.empty(maxLength)\n",
    "        a.fill(user)\n",
    "        if len(TargetUser) < 1:\n",
    "            TargetUser=a\n",
    "        else:\n",
    "            TargetUser=np.concatenate((TargetUser,a))\n",
    "        row=0\n",
    "        for userF in usersFV[user]:\n",
    "            column=0\n",
    "            if userF==0:\n",
    "                userF=[]\n",
    "            availableValuesCount=len(userF)\n",
    "            sum=0\n",
    "            for value in userF:\n",
    "                userData[column][row]=value\n",
    "                column=column+1\n",
    "                sum=sum+value\n",
    "            if availableValuesCount==0:\n",
    "                mean=0\n",
    "            else:\n",
    "                mean=sum/availableValuesCount\n",
    "            gussianValues=np.random.normal(mean,3,maxLength-availableValuesCount)\n",
    "            for value in gussianValues:\n",
    "            \n",
    "                userData[column][row]=value\n",
    "                column=column+1\n",
    "        \n",
    "            row=row+1\n",
    "        print(userData.shape)\n",
    "        if len(GMMData)==0:\n",
    "            GMMData=userData\n",
    "        else:\n",
    "            GMMData=np.append(GMMData,userData,axis=0)\n",
    "            \n",
    "        \n",
    "    return GMMData,TargetUser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from statsmodels.nonparametric.kernel_density import KDEMultivariate\n",
    "\n",
    "class KDEClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"Bayesian generative classification based on KDE\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    bandwidth : float\n",
    "        the kernel bandwidth within each class\n",
    "    kernel : str\n",
    "        the kernel name, passed to KernelDensity\n",
    "    \"\"\"\n",
    "    def __init__(self, bandwidth=1.0, kernel='gaussian'):\n",
    "        self.bandwidth = bandwidth\n",
    "        self.kernel = kernel\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.sort(np.unique(y))\n",
    "        training_sets = [X[y == yi] for yi in self.classes_]\n",
    "        self.models_ = [KernelDensity(bandwidth=self.bandwidth,\n",
    "                                      kernel=self.kernel).fit(Xi)\n",
    "                        for Xi in training_sets]\n",
    "        self.logpriors_ = [np.log(Xi.shape[0] / X.shape[0])\n",
    "                           for Xi in training_sets]\n",
    "        return self\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        logprobs = np.array([model.score_samples(X)\n",
    "                             for model in self.models_]).T\n",
    "        result = np.exp(logprobs + self.logpriors_)\n",
    "        return result / result.sum(1, keepdims=True)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.classes_[np.argmax(self.predict_proba(X), 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001100\n",
      "(62, 676)\n",
      "002100\n",
      "(57, 676)\n",
      "003100\n",
      "(57, 676)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files=ReadListOfTextFilesFromDirectoryWalk(\"..\\\\UB_keystroke_dataset\\\\S1\")\n",
    "# I am training on first 10 users\n",
    "dataFileFormat=CreateListOfTuplesFromFile(files[0:6:2])\n",
    "#print(dataFileFormat[0])\n",
    "df=CreateDataFrame(dataFileFormat,columns=['Key', 'EventType','Time','User'])\n",
    "alphabetsDF=ParseAlphabetsKeys(df)\n",
    "keyDownDownTimeDifference=GetTimeDifferenceofKeyDownDown(data=alphabetsDF)\n",
    "FeatureVectors=GetDictionaryOfFeatureVectors(keyDownDownTimeDifference) \n",
    "usersFV=pd.DataFrame.from_dict(FeatureVectors)\n",
    "X,y=GetKDEFormatDataFromDataFrame(usersFV)\n",
    "KDE=KDEClassifier()\n",
    "KDE.fit(X,y)\n",
    "KDE.predict_proba(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001100\n",
      "(62, 676)\n",
      "002100\n",
      "(57, 676)\n",
      "003100\n",
      "(57, 676)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ammar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100.,\n",
       "       1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100.,\n",
       "       1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100.,\n",
       "       1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100.,\n",
       "       1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100.,\n",
       "       1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100.,\n",
       "       1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100.,\n",
       "       1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100.,\n",
       "       1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100.,\n",
       "       1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100.,\n",
       "       1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100.,\n",
       "       1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100.,\n",
       "       1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100.,\n",
       "       1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100.,\n",
       "       1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100.,\n",
       "       1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100.,\n",
       "       1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100.,\n",
       "       1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100.,\n",
       "       1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100., 1100.,\n",
       "       1100., 1100., 1100., 1100., 1100.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files=ReadListOfTextFilesFromDirectoryWalk(\"..\\\\UB_keystroke_dataset\\\\S1\")\n",
    "# I am training on first 10 users\n",
    "dataFileFormat=CreateListOfTuplesFromFile(files[0:6:2])\n",
    "#print(dataFileFormat[0])\n",
    "df=CreateDataFrame(dataFileFormat,columns=['Key', 'EventType','Time','User'])\n",
    "alphabetsDF=ParseAlphabetsKeys(df)\n",
    "keyDownDownTimeDifference=GetTimeDifferenceofKeyDownDown(data=alphabetsDF)\n",
    "FeatureVectors=GetDictionaryOfFeatureVectors(keyDownDownTimeDifference) \n",
    "usersFV=pd.DataFrame.from_dict(FeatureVectors)\n",
    "X_test,y=GetKDEFormatDataFromDataFrame(usersFV)\n",
    "KDE.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetDictOfDiagraphs(keyDownDownTimeDifference):\n",
    "    feature_vec = dict()\n",
    "    for key_DD_time in keyDownDownTimeDifference:\n",
    "        key_DD = key_DD_time[0] + key_DD_time[1]\n",
    "        if key_DD not in feature_vec:\n",
    "            feature_vec[key_DD] = []\n",
    "        feature_vec[key_DD].append(key_DD_time[2])\n",
    "    return feature_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetDictOfGMMs(feature_vec):\n",
    "    dict_gmms = dict()\n",
    "    for key, value in feature_vec.items():\n",
    "        #print (key + \" - \" + str(len(value)))\n",
    "        if len(value) > 9:\n",
    "            #train GMM\n",
    "            #FeatureGMMdic[key] = GMM Mode\n",
    "            gmm = mixture.GaussianMixture(n_components=1, covariance_type='spherical')\n",
    "\n",
    "            gmm.fit(np.array(value).reshape(-1,1))\n",
    "            dict_gmms[key] = gmm\n",
    "    return dict_gmms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModelforEachDiagraph(user):\n",
    "    dataFileFormat=CreateListFromFile(user)\n",
    "    #print(dataFileFormat[0])\n",
    "    df=CreateDataFrame(dataFileFormat,columns=['Key', 'EventType','Time','User'])\n",
    "    alphabetsDF=ParseAlphabetsKeys(df)\n",
    "    keyDownDownTimeDifference=GetTimeDifferenceofKeyDownDown(data=alphabetsDF)\n",
    "    \n",
    "    return GetDictOfGMMs(GetDictOfDiagraphs(keyDownDownTimeDifference))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestModelforEachDiagraph(user, dict_gmms):\n",
    "    dataFileFormat=CreateListFromFile(user)\n",
    "    df=CreateDataFrame(dataFileFormat,columns=['Key', 'EventType','Time','User'])\n",
    "    alphabetsDF=ParseAlphabetsKeys(df)\n",
    "    keyDownDownTimeDifference=GetTimeDifferenceofKeyDownDown(data=alphabetsDF)\n",
    "    #print (GetDictOfDiagraphs(keyDownDownTimeDifference))\n",
    "    for key, value in GetDictOfDiagraphs(keyDownDownTimeDifference).items():\n",
    "        if key in dict_gmms and len(value) > 9:\n",
    "            print(dict_gmms[key].score(np.array(value).reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"..\\\\UB_keystroke_dataset\\\\S0\"\n",
    "users=ReadListOfTextFilesFromDirectoryWalk(path)\n",
    "\n",
    "diagraps_gmms = TrainModelforEachDiagraph(users[0])\n",
    "#diagraps_gmms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-104.23862759247639\n",
      "-6.760980977428194\n",
      "-6.8174054099162245\n",
      "-7.193345086861418\n",
      "-6.903618620738496\n",
      "-7.576416676409476\n",
      "-6.926767302998269\n",
      "-7.214633397714556\n",
      "-6.3478029449399305\n",
      "-7.247702955179273\n",
      "-6.380801912206913\n",
      "-5.8300183883013315\n",
      "-7.622594942359484\n",
      "-5.87642620020031\n",
      "-5.364325150006197\n",
      "-6.149095329464601\n",
      "-5.4964308365100525\n",
      "-6.1898654734225165\n",
      "-6.856193049900927\n",
      "-6.178947282329126\n",
      "-6.960858808095388\n",
      "-6.632949026851759\n",
      "-6.720055891465157\n",
      "-6.910542356964444\n",
      "-7.644731207881364\n",
      "-5.490434900343557\n",
      "-10.093168743625723\n",
      "-8.96632051388883\n",
      "-11.017851765571965\n",
      "-5.796038927700559\n",
      "-7.17292003303358\n",
      "-31.257288246598392\n",
      "-7.605045439708615\n",
      "-5.870773174970111\n",
      "-13.181258784678333\n",
      "-5.646672643012161\n",
      "-7.18025078139989\n",
      "-21.169112182298033\n",
      "-7.233822232462447\n",
      "-5.479294232246047\n",
      "-7.3956916322255655\n",
      "-6.3190571566138765\n",
      "-7.306617315213329\n",
      "-90.57369880944525\n",
      "-7.840823151823784\n",
      "-12.00979880811829\n",
      "-6.144023583122098\n",
      "-28.262586564537305\n",
      "-7.350894547226071\n",
      "-6.936640270194664\n",
      "-6.513974942067512\n",
      "-7.626217551705693\n",
      "-7.302392951200141\n",
      "-7.715621780157255\n",
      "-6.286162404845391\n",
      "-5.616153646553445\n",
      "-6.044275011047327\n",
      "-7.1345568407347235\n",
      "-7.357496964586729\n",
      "-24.50366943467092\n",
      "-11.806324578409267\n",
      "-10.150289025692423\n",
      "-6.025045689111786\n",
      "-7.2282833287203205\n",
      "-6.076199939511839\n",
      "-6.607411776447586\n",
      "-7.433367187441445\n",
      "-6.185310619567062\n",
      "-6.426322555624794\n",
      "-7.114290443795429\n",
      "-9.027840800035923\n",
      "-5.6917330316939\n",
      "-6.855769164621843\n",
      "-11.158726667753404\n",
      "-5.506001245853872\n",
      "-6.260815961462891\n",
      "-7.909256592600798\n",
      "-6.232446109370901\n",
      "-6.701555611427182\n",
      "-7.10425929069063\n",
      "-7.634384510364606\n",
      "-5.803209732437416\n",
      "-18.433423880113306\n",
      "-9.610613095557222\n",
      "-6.730538165322299\n"
     ]
    }
   ],
   "source": [
    "TestModelforEachDiagraph(users[6],diagraps_gmms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
