{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn import mixture\n",
    "import pandas as pd\n",
    "import re\n",
    "import scipy.stats as stats\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadListOfTextFilesFromDirectoryWalk(path):\n",
    "    \"\"\"Read all text files from given directory and its sudirectories and return list of text files path\"\"\"\n",
    "    files = []\n",
    "    # r=root, d=directories, f = files\n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f:\n",
    "            if '.txt' in file:\n",
    "                files.append(os.path.join(r, file))\n",
    "    return files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateListOfTuplesFromFile(files):\n",
    "#Reading file and create tuple \n",
    "    items = []\n",
    "    for file in files:\n",
    "        filename=file.split('\\\\')[-1].split('.')[0]\n",
    "        f=open(file, \"r\")\n",
    "        for line in f:\n",
    "            words= line.rstrip('\\n').split(sep=\" \")\n",
    "            items.append((words[0],words[1],words[2],filename))\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dataframes\n",
    "def CreateDataFrame(items,columns):\n",
    "    \"\"\"Taking list of tuples and return dataframe\"\"\"\n",
    "    df = pd.DataFrame.from_records(items, columns=['Key', 'EventType','Time','User'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ParseAlphabetsKeys(df):\n",
    "    \"\"\"Return only alphabets records\"\"\"\n",
    "    dfAlphabets=df[df[\"Key\"].str.match('^.*[A-Z]$')]\n",
    "    return dfAlphabets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTimeDifferenceofKeyDownDown(data):\n",
    "    prev=0\n",
    "    rows=[]\n",
    "    for index,row in data.iterrows():\n",
    "        if prev==0 and row[1]==\"KeyDown\":\n",
    "            prevRow=row\n",
    "            prev=1\n",
    "        elif row[1]==\"KeyDown\":\n",
    "            rows.append([ prevRow[0], row[0], int(row[2])- int(prevRow[2]),row[3]])\n",
    "            prevRow=row\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetDictionaryOfFeatureVectors(keyDownDownTimeDifference):\n",
    "    \"\"\"\n",
    "    Take List of arrays and return dictionary of 26*26 vector for each user\n",
    "    \"\"\"\n",
    "    dictFV=dict()\n",
    "    for xi in keyDownDownTimeDifference:\n",
    "        if xi[3] not in dictFV:\n",
    "            dictFV[xi[3]]=np.zeros(26*26,dtype=object)\n",
    "            \n",
    "        index=(ord(xi[0])-65)*26+np.absolute(ord(xi[1])-65)\n",
    "        if dictFV[xi[3]][index]==0:\n",
    "            dictFV[xi[3]][index]=[]\n",
    "        if xi[2] < 1000:\n",
    "            dictFV[xi[3]][index].append(xi[2])\n",
    "    return dictFV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetGMMFormatDataFromDataFrame(usersFV):\n",
    "    GMMData=[]\n",
    "    for user in usersFV.columns:\n",
    "        maxLength=0\n",
    "        for userF in usersFV[user]:\n",
    "            if userF==0:\n",
    "                userF=[]\n",
    "            featureLenght=len(userF)\n",
    "            if featureLenght > maxLength:\n",
    "                maxLength=featureLenght\n",
    "        userDF=pd.DataFrame(index=range(0,676))\n",
    "        userData=np.zeros((maxLength,676))\n",
    "        row=0\n",
    "        for userF in usersFV[user]:\n",
    "            column=0\n",
    "            if userF==0:\n",
    "                userF=[]\n",
    "            availableValuesCount=len(userF)\n",
    "            sum=0\n",
    "            for value in userF:\n",
    "                userData[column][row]=value\n",
    "                column=column+1\n",
    "                sum=sum+value\n",
    "            if availableValuesCount==0:\n",
    "                mean=0\n",
    "            else:\n",
    "                mean=sum/availableValuesCount\n",
    "            gussianValues=np.random.normal(mean,3,maxLength-availableValuesCount)\n",
    "            for value in gussianValues:\n",
    "            \n",
    "                userData[column][row]=value\n",
    "                column=column+1\n",
    "        \n",
    "            row=row+1\n",
    "        print(userData.shape)\n",
    "        if len(GMMData)==0:\n",
    "            GMMData=userData\n",
    "        else:\n",
    "            GMMData=np.append(GMMData,userData,axis=0)\n",
    "    return GMMData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAverageFeatureVectors(FeatureVectors):\n",
    "    \n",
    "    averageFV= np.zeros(26*26,dtype=object)\n",
    "    index=0\n",
    "    for xi in FeatureVectors:\n",
    "        tempSum=np.array(xi).sum()\n",
    "        if type(xi)== list:\n",
    "            averageFV[index]=tempSum/len(xi)\n",
    "        index=index+1\n",
    "    return averageFV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel(path):\n",
    "    \"\"\"Get path of data files and train a GMM model\"\"\"\n",
    "    files=ReadListOfTextFilesFromDirectoryWalk(path)\n",
    "    # I am training on first 10 users\n",
    "    dataFileFormat=CreateListOfTuplesFromFile(files[0:6:2])\n",
    "    #print(dataFileFormat[0])\n",
    "    df=CreateDataFrame(dataFileFormat,columns=['Key', 'EventType','Time','User'])\n",
    "    alphabetsDF=ParseAlphabetsKeys(df)\n",
    "    keyDownDownTimeDifference=GetTimeDifferenceofKeyDownDown(data=alphabetsDF)\n",
    "    FeatureVectors=GetDictionaryOfFeatureVectors(keyDownDownTimeDifference) \n",
    "    usersFV=pd.DataFrame.from_dict(FeatureVectors)\n",
    "    data= GetGMMFormatDataFromDataFrame(usersFV)\n",
    "    g = mixture.GMM(n_components=3)\n",
    "    print(len(data))\n",
    "    g.fit(data)\n",
    "    return g\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestModel(path,g):\n",
    "    \"\"\"Get path of data files and test a GMM model\"\"\"\n",
    "    GMMData=[]\n",
    "    files=ReadListOfTextFilesFromDirectoryWalk(path)\n",
    "    dataFileFormat=CreateListOfTuplesFromFile(files[0:6:2])\n",
    "    df=CreateDataFrame(dataFileFormat,columns=['Key', 'EventType','Time','User'])\n",
    "    \n",
    "    alphabetsDF=ParseAlphabetsKeys(df)\n",
    "    keyDownDownTimeDifference=GetTimeDifferenceofKeyDownDown(data=alphabetsDF)\n",
    "    FeatureVectors=GetDictionaryOfFeatureVectors(keyDownDownTimeDifference) \n",
    "    usersFV=pd.DataFrame.from_dict(FeatureVectors)\n",
    "    for user in FeatureVectors:\n",
    "        print(user)\n",
    "        data=GetAverageFeatureVectors(FeatureVectors[user])\n",
    "        dataNP=np.array(data,dtype=np.float64)\n",
    "        dataNP[np.isnan(dataNP)]=0\n",
    "        dataNP=dataNP.reshape((1,676))\n",
    "        \n",
    "        \n",
    "        if len(GMMData)==0:\n",
    "            GMMData=dataNP\n",
    "        else:\n",
    "            GMMData=np.append(GMMData,dataNP,axis=0)\n",
    "    print(GMMData.shape)\n",
    "    print(len(GMMData))\n",
    "    \n",
    "    print(g.predict_proba(GMMData))\n",
    "    return g.predict(GMMData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65, 676)\n",
      "(65, 676)\n",
      "(65, 676)\n",
      "195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umsan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class GMM is deprecated; The class GMM is deprecated in 0.18 and will be  removed in 0.20. Use class GaussianMixture instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Muhammad Umsan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Muhammad Umsan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Muhammad Umsan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Muhammad Umsan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.33333333, 0.33333333, 0.33333333])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GMM= TrainModel(\"..\\\\UB_keystroke_dataset\\\\S0\")\n",
    "GMM.weights_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001100\n",
      "002100\n",
      "003100\n",
      "(3, 676)\n",
      "3\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umsan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "C:\\Users\\Muhammad Umsan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Muhammad Umsan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "predictions=TestModel(\"..\\\\UB_keystroke_dataset\\\\S1\",GMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
